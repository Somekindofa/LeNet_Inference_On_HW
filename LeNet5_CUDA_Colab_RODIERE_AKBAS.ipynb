{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrqDziDGX8Lg"
      },
      "source": [
        "# CUDA compatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iOMJeczRJku",
        "outputId": "23494fb2-0ae2-474b-e44d-96451144b50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "  !nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQO0DC5CRm1o",
        "outputId": "2fc86e5a-5845-4250-c935-bc0dd9ecc33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-8y_e0n3y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-8y_e0n3y\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4716 sha256=738359a4a6ee049fd9c13d09794d0ee24b52b538e7362bed6198f9a40e5ea09b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5yyw_h9p/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OPXvI_fRsRY",
        "outputId": "69e3be32-fde3-4041-b4dd-750d25fb0a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhHT6RfZYFNQ"
      },
      "source": [
        "# A few tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlBvCMhzR9qv",
        "outputId": "1bf4cd44-487f-440b-ad71-95b2a5b1a49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, from the CPU!\n",
            "Hello, from the GPU!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "// __global__ keyword specifies a device kernel function\n",
        "__global__ void kernelA(){\n",
        "    printf(\"Hello, from the GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    printf(\"Hello, from the CPU!\\n\");\n",
        "\n",
        "    // Set which device should be used\n",
        "    // The code will default to 0 if not called though\n",
        "    cudaSetDevice(0);\n",
        "\n",
        "    // Call a device function from the host: a kernel launch\n",
        "    // Which will print from the device\n",
        "    kernelA <<<1,1>>>();\n",
        "\n",
        "    // This call waits for all of the submitted GPU work to complete\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "   return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI7R9jHHS2km",
        "outputId": "a778f469-5a85-43c7-f968-cd31f6f99b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out[0] = 3.000000\n",
            "PASSED\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 10000000\n",
        "#define MAX_ERR 1e-6\n",
        "\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out;\n",
        "\n",
        "    // Allocate memory\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "    // Initialize array\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = 1.0f;\n",
        "        b[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    cudaMalloc((void**)&d_a, sizeof(float)*N);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float)*N);\n",
        "    cudaMalloc((void**)&d_out, sizeof(float)*N);\n",
        "\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Main function\n",
        "    vector_add<<<1,1>>>(d_out, d_a, d_b, N);\n",
        "\n",
        "    cudaMemcpy(out, d_out, sizeof(float)*N, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Verification\n",
        "    for(int i = 0; i < N; i++){\n",
        "        assert(fabs(out[i] - a[i] - b[i]) < MAX_ERR);\n",
        "    }\n",
        "    printf(\"out[0] = %f\\n\", out[0]);\n",
        "    printf(\"PASSED\\n\");\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi79yuYKYG71"
      },
      "source": [
        "# LeNet5 inference in CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciVj4IQxTBzx",
        "outputId": "b18f2655-2bf9-41f3-da77-b314efff2517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A0[:,:]=\n",
            "1.000000\t2.000000\t3.000000\t4.000000\t\n",
            "5.000000\t6.000000\t7.000000\t8.000000\t\n",
            "9.000000\t10.000000\t11.000000\t12.000000\t\n",
            "13.000000\t14.000000\t15.000000\t16.000000\t\n",
            "\n",
            "B[:,:]=\n",
            "1.000000\t0.000000\t\n",
            "0.000000\t1.000000\t\n",
            "\n",
            "A[0,:,:]=\n",
            "1.000000\t2.000000\t3.000000\t4.000000\t\n",
            "5.000000\t6.000000\t7.000000\t8.000000\t\n",
            "9.000000\t10.000000\t11.000000\t12.000000\t\n",
            "13.000000\t14.000000\t15.000000\t16.000000\t\n",
            "\n",
            "A[1,:,:]=\n",
            "1.000000\t0.000000\t0.000000\t0.000000\t\n",
            "0.000000\t1.000000\t0.000000\t0.000000\t\n",
            "0.000000\t0.000000\t1.000000\t0.000000\t\n",
            "0.000000\t0.000000\t0.000000\t1.000000\t\n",
            "\n",
            "C[0,0,:,:]=\n",
            "1.000000\t0.000000\t\n",
            "0.000000\t1.000000\t\n",
            "\n",
            "C[0,1,:,:]=\n",
            "2.000000\t0.000000\t\n",
            "0.000000\t2.000000\t\n",
            "\n",
            "C[1,0,:,:]=\n",
            "2.000000\t0.000000\t\n",
            "0.000000\t2.000000\t\n",
            "\n",
            "C[1,1,:,:]=\n",
            "1.000000\t0.000000\t\n",
            "0.000000\t1.000000\t\n",
            "\n",
            "bias=\n",
            "1.000000\t2.000000\t\n",
            "\n",
            "A0 conv B on CPU:\n",
            "7.000000\t9.000000\t11.000000\t\n",
            "15.000000\t17.000000\t19.000000\t\n",
            "23.000000\t25.000000\t27.000000\t\n",
            "\n",
            "A0 conv B on GPU:\n",
            "7.000000\t9.000000\t11.000000\t\n",
            "15.000000\t17.000000\t19.000000\t\n",
            "23.000000\t25.000000\t27.000000\t\n",
            "\n",
            "A conv C on CPU (2 in channels, 2 out channel) - 1st output channel:\n",
            "11.000000\t9.000000\t11.000000\t\n",
            "15.000000\t21.000000\t19.000000\t\n",
            "23.000000\t25.000000\t31.000000\t\n",
            "\n",
            "A conv C on CPU (2 in channels, 2 out channel) - 2nd output channel:\n",
            "16.000000\t18.000000\t22.000000\t\n",
            "30.000000\t36.000000\t38.000000\t\n",
            "46.000000\t50.000000\t56.000000\t\n",
            "\n",
            "A conv C on GPU (2 in channels, 2 out channel) - 1st output channel:\n",
            "7.000000\t9.000000\t11.000000\t\n",
            "15.000000\t17.000000\t19.000000\t\n",
            "23.000000\t25.000000\t27.000000\t\n",
            "\n",
            "A conv C on GPU (2 in channels, 2 out channel) - 2nd output channel:\n",
            "7.000000\t9.000000\t11.000000\t\n",
            "15.000000\t17.000000\t19.000000\t\n",
            "23.000000\t25.000000\t27.000000\t\n",
            "\n",
            "2x2 average pooling of A on CPU:\n",
            "\n",
            "Ap[0,:,:]\n",
            "3.500000\t5.500000\t\n",
            "11.500000\t13.500000\t\n",
            "\n",
            "Ap[1,:,:]\n",
            "0.500000\t0.000000\t\n",
            "0.000000\t0.500000\t\n",
            "\n",
            "2x2 average pooling of A on GPU:\n",
            "\n",
            "Ap[0,:,:]\n",
            "3.500000\t5.500000\t\n",
            "11.500000\t13.500000\t\n",
            "\n",
            "Ap[1,:,:]\n",
            "0.500000\t0.000000\t\n",
            "0.000000\t0.500000\t\n",
            "\n",
            "A plus bias on CPU - 1st channel:\n",
            "2.000000\t3.000000\t4.000000\t5.000000\t\n",
            "6.000000\t7.000000\t8.000000\t9.000000\t\n",
            "10.000000\t11.000000\t12.000000\t13.000000\t\n",
            "14.000000\t15.000000\t16.000000\t17.000000\t\n",
            "\n",
            "A plus bias on CPU - 2nd channel:\n",
            "3.000000\t2.000000\t2.000000\t2.000000\t\n",
            "2.000000\t3.000000\t2.000000\t2.000000\t\n",
            "2.000000\t2.000000\t3.000000\t2.000000\t\n",
            "2.000000\t2.000000\t2.000000\t3.000000\t\n",
            "\n",
            "A plus bias on GPU - 1st channel:\n",
            "2.000000\t3.000000\t4.000000\t5.000000\t\n",
            "6.000000\t7.000000\t8.000000\t9.000000\t\n",
            "10.000000\t11.000000\t12.000000\t13.000000\t\n",
            "14.000000\t15.000000\t16.000000\t17.000000\t\n",
            "\n",
            "A plus bias on GPU - 2nd channel:\n",
            "3.000000\t2.000000\t2.000000\t2.000000\t\n",
            "2.000000\t3.000000\t2.000000\t2.000000\t\n",
            "2.000000\t2.000000\t3.000000\t2.000000\t\n",
            "2.000000\t2.000000\t2.000000\t3.000000\t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h> //cuda math library\n",
        "void randomMatrixInit(float *M, int n, int p){\n",
        "/*\n",
        "Initializes matrix M of size n*p with values uniformly sampled between 0 and 1.\n",
        "\n",
        "Inputs:\n",
        "\t-M: Matrix initialized by dynamic memory allocation (float*) M = (float*) malloc(n*p*sizeof(float))\n",
        "\t-n: number of lines of M\n",
        "\t-p: number of columns of M\n",
        "*/\n",
        "\tfor (int i=0;i<n;i++){\n",
        "\t\tfor(int j=0;j<p;j++){\n",
        "\t\t\t//M[i][j] -> *(M+i*p+j) linearizing the indices\n",
        "\t\t\tM[i*p+j ]=(float) rand()/RAND_MAX;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "void random3DArrayInit(float *A, int n_channels, int n, int p){\n",
        "/*\n",
        "Initializes matrix A of size n_channels*n*p with values uniformly sampled between 0 and 1.\n",
        "\n",
        "Inputs:\n",
        "\t-A: Array initialized by dynamic memory allocation (float*) A = (float*) malloc(n_channels*n*p*sizeof(float))\n",
        "\t-n_channels: number of channels of A\n",
        "\t-n: number of lines of each channel of A\n",
        "\t-p: number of columns of each channel of A\n",
        "*/\n",
        "\tfor (int c=0;c<n_channels;c++){\n",
        "\t\tfor (int i=0;i<n;i++){\n",
        "\t\t\tfor(int j=0;j<p;j++){\n",
        "\t\t\t\t//A[c][i][j] -> A[c*n*n+i*p+j] linearizing the indices\n",
        "\t\t\t\tA[c*n*n+i*p+j]=(float) rand()/RAND_MAX;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "void random4DArrayInit(float *A, int n_in_channels, int n_out_channels,int n, int p){\n",
        "/*\n",
        "Initializes array A of size n_out_channels*n_in_channels*n*p with values uniformly sampled between 0 and 1.\n",
        "\n",
        "Inputs:\n",
        "\t-A: Array initialized by dynamic memory allocation (float*) A = (float*) malloc(n_out_channels*n_in_channels*n*p*sizeof(float))\n",
        "\t-n_in_channels: number of input channels of A\n",
        "\t-n_out_channels: number of output channels of A\n",
        "\t-n: number of lines of each channel of A\n",
        "\t-p: number of columns of each channel of A\n",
        "*/\n",
        "\tfor (int c_out=0;c_out<n_out_channels;c_out++){\n",
        "\t\tfor (int c_in=0;c_in<n_in_channels;c_in++){\n",
        "\t\t\tfor (int i=0;i<n;i++){\n",
        "\t\t\t\tfor(int j=0;j<p;j++){\n",
        "\t\t\t\t\t//A[c][i][j] -> A[c*n*n+i*p+j] linearizing the indices\n",
        "\t\t\t\t\tA[c_out*n_in_channels*n*n+c_in*n*n+i*p+j]=(float) rand()/RAND_MAX;\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "void zero3DArrayInit(float *A, int n_channels, int n, int p){\n",
        "/*\n",
        "Initializes matrix A of size n_channels*n*p with zeros.\n",
        "\n",
        "Inputs:\n",
        "\t-A: Array initialized by dynamic memory allocation (float*) A = (float*) malloc(n_channels*n*p*sizeof(float))\n",
        "\t-n_channels: number of channels of A\n",
        "\t-n: number of lines of each channel of A\n",
        "\t-p: number of columns of each channel of A\n",
        "*/\n",
        "\tfor (int c=0;c<n_channels;c++){\n",
        "\t\tfor (int i=0;i<n;i++){\n",
        "\t\t\tfor(int j=0;j<p;j++){\n",
        "\t\t\t\t//A[c][i][j] -> *(A+c*n^2+i*p+j) linearizing the indices\n",
        "\t\t\t\tA[c*n*n+i*p+j]=0;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "void AddBias(float *A, float* Bias, float* Output, int n_channels, int Mat_size){\n",
        "/*\n",
        "Adds Bias to 3D array A. The bias is added as a matrix where each element is the same\n",
        "\n",
        "Inputs:\n",
        "\t-A: 3D array of shape n_channels*Mat_size*Mat_size\n",
        "\t-Bias: 1D Vector of length n_channels\n",
        "\t-Output: the output array of shape n_channels*Mat_size*Mat_size, allocated with malloc\n",
        "\t-Mat_size: Size of each channel of A\n",
        "\t-n_channels: Number of channels of A\n",
        "*/\n",
        "\tfor(int channel_no=0;channel_no<n_channels;channel_no++){\n",
        "\t\tfloat b=Bias[channel_no];\n",
        "\t\tfor(int i=0;i<Mat_size;i++){\n",
        "\t\t\tfor(int j=0;j<Mat_size;j++){\n",
        "\t\t\t\tint index=channel_no*Mat_size*Mat_size+i*Mat_size+j;\n",
        "\t\t\t\tOutput[index]=A[index]+b;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void cudaAddBias(float *A, float* Bias, float* Output, int n_channels, int Mat_size){\n",
        "/*\n",
        "Adds Bias to 3D array A. The bias is added as a matrix where each element is the same\n",
        "\n",
        "Inputs:\n",
        "\t-A: 3D array of shape n_channels*Mat_size*Mat_size\n",
        "\t-Bias: 1D Vector of length n_channels\n",
        "\t-Output: the output array of shape n_channels*Mat_size*Mat_size, allocated with malloc\n",
        "\t-Mat_size: Size of each channel of A\n",
        "\t-n_channels: Number of channels of A\n",
        "\n",
        "Each thread takes care of one addition, we assume:\n",
        "\t-gridDim.x=n_channels\n",
        "\t-gridDim.y=1\n",
        "\t-gridDim.z=1\n",
        "\t-blockDim.x=Mat_size\n",
        "\t-blockDim.y=Mat_size\n",
        "\t-blockDim.z=1\n",
        "\n",
        "Thus:\n",
        "\t-channel_no=blockIdx.x\n",
        "\t-i=threadIdx.x\n",
        "\t-j=threadIdx.y\n",
        "*/\n",
        "\tint channel_no=blockIdx.x;\n",
        "\tint i=threadIdx.x;\n",
        "\tint j=threadIdx.y;\n",
        "\tint index=channel_no*Mat_size*Mat_size+i*Mat_size+j;\n",
        "\tOutput[index]=A[index]+Bias[channel_no];\n",
        "}\n",
        "\n",
        "void Conv2D(float *Mat, float *Kernels, float *Output, int n_in_channels, int n_out_channels, int Mat_size, int Kernel_size){\n",
        "/*\n",
        "Returns the *valid* convolution with stride=1, padding=1 between Matrix and Kernel, computed on CPU.\n",
        "\n",
        "Inputs:\n",
        "\t-Mat: Input square matrix of size no_input_channels*Mat_size*Mat_size (no depth!)\n",
        "\tinitialized by dynamic memory allocation (float*) Mat = (float*) malloc(Mat_size*Mat_size*sizeof(float))\n",
        "\t-Kernels: Input square convolution kernel of size n_out_channels*n_in_channels*Kernel_size*Kernel_size, initalized in the same way\n",
        "\t-Output: Output array of shape no_output_channels*(Mat_size-Kernel_size+1)*(Mat_size-Kernel_size+1), initalized in the same way\n",
        "\t-n_in_channels: Number of input channels\n",
        "\t-n_out_channels: Number of output channels\n",
        "\t-Mat_size: Matrix size\n",
        "\t-Kernel_size: Kernel size\n",
        "*/\n",
        "\tint Output_size = Mat_size - Kernel_size +1;\n",
        "\tfor (int in_channel_no=0;in_channel_no<n_in_channels;in_channel_no++){\n",
        "\t\tfor (int out_channel_no=0;out_channel_no<n_out_channels;out_channel_no++){\n",
        "\t\t\tfor (int horizontal_block_id=0; horizontal_block_id<Output_size;horizontal_block_id++){\n",
        "\t\t\t\tfor (int vertical_block_id=0;vertical_block_id<Output_size;vertical_block_id++){\n",
        "\t\t\t\t\tfloat block_output=0;\n",
        "\t\t\t\t\tfor (int i=0;i<Kernel_size;i++){\n",
        "\t\t\t\t\t\tfor (int j=0;j<Kernel_size;j++){\n",
        "\t\t\t\t\t\t\t//the index of the Matrix with the right channel number, the right vertical and horizontal block and right i and j indexes inside the block\n",
        "\t\t\t\t\t\t\tint mat_index=in_channel_no*Mat_size*Mat_size+(horizontal_block_id+i)*Mat_size+vertical_block_id+j;\n",
        "\t\t\t\t\t\t\t//the index of the kernel with the right input and output channel index and the right position (i,j) inside the kernel\n",
        "\t\t\t\t\t\t\tint kernel_index=out_channel_no*n_in_channels*Kernel_size*Kernel_size + in_channel_no*Kernel_size*Kernel_size + i*Kernel_size+j;\n",
        "\t\t\t\t\t\t\tblock_output=block_output+Mat[mat_index] * Kernels[kernel_index];\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\tint output_index=out_channel_no*Output_size*Output_size + horizontal_block_id*Output_size + vertical_block_id;\n",
        "\t\t\t\t\tOutput[output_index]+=block_output;\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void cudaConv2D(float *Mat, float *Kernels, float *Output, int n_in_channels, int n_out_channels, int Mat_size, int Kernel_size) {\n",
        "/*\n",
        "Returns the *valid* convolution with stride=1, padding=1 between Matrix (square) and Kernels (square), computed on GPU using CUDA.\n",
        "We assume:\n",
        "\t-gridDim.x=Output_size\n",
        "\t-gridDim.y=Output_size\n",
        "\t-gridDim.z=1\n",
        "\t-blockDim.x=n_in_channels\n",
        "\t-blockDim.y=n_out_channels\n",
        "\t-blockDim.z=1\n",
        "\t-Dynamic memory allocation of 2*Kernel_size*Kernel_size*sizeof(float) (third argument in the <<< >>> brackets) to share block weights for all channels\n",
        "\n",
        "We have:\n",
        "\t-in_channel_no=blockIdx.x\n",
        "\t-out_channel_no=blockIdx.y\n",
        "\t-horizontal_block_id=threadIdx.x\n",
        "\t-vertical_block_id=threadIdx.y\n",
        "\n",
        "Each thread block computes a convolution block for all input and output channel pairs and aggregates them.\n",
        "\n",
        "Inputs:\n",
        "\t-Mat: Input square matrix of size no_in_channels*Mat_size*Mat_size\n",
        "\tinitialized by dynamic memory allocation (float*) Mat = (float*) malloc(no_in_channels*Mat_size*Mat_size*sizeof(float))\n",
        "\t-Kernels: Input square convolution kernel of size n_out_channels*n_in_chanels*Kernel_size*Kernel_size, initalized in the same way\n",
        "\t-Output: Output array of shape no_out_channels*Output_size*Output_size, initalized in the same way\n",
        "\t-n_in_channels: Number of input channels\n",
        "\t-n_out_channels: Number of output channels\n",
        "\t-Mat_size: Matrix size\n",
        "\t-Kernel_size: Kernel size\n",
        "*/\n",
        "\n",
        "    int Output_size = Mat_size - Kernel_size + 1;\n",
        "    int horizontal_block_id = blockIdx.x;\n",
        "    int vertical_block_id = blockIdx.y;\n",
        "    int in_channel_no = threadIdx.x;\n",
        "    int out_channel_no = threadIdx.y;\n",
        "\n",
        "    // Dynamic shared memory allocation (https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/)\n",
        "    extern __shared__ float shared_memory[]; //size is declared at run time. Must be equal to 2*Kernel_size*Kernel_size*sizeof(float)\n",
        "    float* Mat_shared=&shared_memory[0];\n",
        "    float* Kernels_shared=&shared_memory[Kernel_size*Kernel_size];\n",
        "\n",
        "    float block_output = 0;\n",
        "    int output_index = out_channel_no * Output_size * Output_size + horizontal_block_id * Output_size + vertical_block_id;\n",
        "\n",
        "    // Load data into shared memory\n",
        "    for (int i = 0; i < Kernel_size; i++) {\n",
        "        for (int j = 0; j < Kernel_size; j++) {\n",
        "\t\t\tint mat_index=in_channel_no*Mat_size*Mat_size+(horizontal_block_id+i)*Mat_size+vertical_block_id+j;\n",
        "\t\t\tint kernel_index=out_channel_no*n_in_channels*Kernel_size*Kernel_size + in_channel_no*Kernel_size*Kernel_size + i*Kernel_size+j;\n",
        "        \tMat_shared[i*Kernel_size+j]=Mat[mat_index];\n",
        "        \tKernels_shared[i*Kernel_size+j]=Kernels[kernel_index];\n",
        "        }\n",
        "    }\n",
        "    // Synchronize threads before using shared memory\n",
        "    __syncthreads();\n",
        "\n",
        "    // Compute convolution\n",
        "    for (int i = 0; i < Kernel_size; i++) {\n",
        "        for (int j = 0; j < Kernel_size; j++) {\n",
        "            float m=Mat_shared[i*Kernel_size+j];\n",
        "            float k=Kernels_shared[i*Kernel_size+j];\n",
        "            block_output = block_output + m*k;\n",
        "        }\n",
        "    }\n",
        "    Output[output_index] += block_output;\n",
        "}\n",
        "\n",
        "void Tanh3D(float* A, float* Output, int n_channels, int Mat_size){\n",
        "/*\n",
        "Returns the tanh of input 3D array A.\n",
        "\n",
        "Inputs:\n",
        "\t-A: Input array of size no_channels*Mat_size*Mat_size\n",
        "\t-Output: Output array of size no_channels*Mat_size*Mat_size\n",
        "\t-no_channels: the number of channels\n",
        "\t-mat_size: the size of the matrix\n",
        "*/\n",
        "\tfor(int channel_no=0;channel_no<n_channels;channel_no++){\n",
        "\t\tfor(int i=0;i<Mat_size;i++){\n",
        "\t\t\tfor(int j=0;j<Mat_size;j++){\n",
        "\t\t\t\tint index=channel_no*Mat_size*Mat_size+i*Mat_size+j;\n",
        "\t\t\t\tOutput[index]=tanh(A[index]);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void cudaTanh3D(float* A,float* Output,int n_channels, int Mat_size){\n",
        "/*\n",
        "Returns the tanh of input 3D array A.\n",
        "\n",
        "We assume:\n",
        "\t-gridDim.x=no_channels\n",
        "\t-blockDim.x=Output_size\n",
        "\t-blockDim.y=Output_size\n",
        "\n",
        "Inputs:\n",
        "\t-A: Input array of size no_channels*Mat_size*Mat_size\n",
        "\t-Output: Output array of size no_channels*Mat_size*Mat_size\n",
        "\t-no_channels: the number of channels\n",
        "\t-mat_size: the size of the matrix\n",
        "*/\n",
        "\tint channel_no=blockIdx.x;\n",
        "\tint i=threadIdx.x;\n",
        "\tint j=threadIdx.y;\n",
        "\tint index=channel_no*Mat_size*Mat_size+i*Mat_size+j;\n",
        "\tOutput[index]=tanh(A[index]);\n",
        "}\n",
        "\n",
        "void AveragePooling2(float *A, float *Output, int n_channels, int A_size){\n",
        "/*\n",
        "Average pooling of the input matrix by a factor of two in both dimensions, using CPU.\n",
        "\n",
        "Inputs:\n",
        "\t-A: Array initialized by dynamic memory allocation (float*) A = (float*) malloc(n_channels*n*p*sizeof(float))\n",
        "\t-Output: Output array, of size n_channels*(A_size/2)*(A_size/2)\n",
        "\t-A_size: number of lines and columns of each channel of A, e.g 28 in the Lenet5 example.\n",
        "\tEach channel is assumed to be a square matrix.\n",
        "\t-n_channels: number of channels of A and Output, e.g 6 in the Lenet5 example\n",
        "\n",
        "Example:\n",
        "\t-If Mat is of size 6*28*28 (Lenet5), output is of size 6*14*14, with averaging of each 2*2 block.\n",
        "*/\n",
        "\n",
        "\tint Output_size = A_size/2;\n",
        "\tfor (int channel_no=0; channel_no<n_channels;channel_no++){\n",
        "\t\tfor (int horizontal_block_id=0; horizontal_block_id<Output_size;horizontal_block_id=horizontal_block_id+1){\n",
        "\t\t\tfor (int vertical_block_id=0;vertical_block_id<Output_size;vertical_block_id=vertical_block_id+1){\n",
        "\n",
        "\t\t\t\t//compute sum over 4*4 block\n",
        "\t\t\t\tfloat block_output=0; //sum of 4*4 block\n",
        "\t\t\t\tfor (int i=0;i<2;i++){\n",
        "\t\t\t\t\tfor (int j=0;j<2;j++){\n",
        "\t\t\t\t\t\tblock_output=block_output + *(A+ channel_no*A_size*A_size + (2*horizontal_block_id+i)*A_size + 2*vertical_block_id+j);\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t\t\tint output_index=channel_no*Output_size*Output_size + horizontal_block_id*Output_size + vertical_block_id;\n",
        "\t\t\t\tOutput[output_index]=block_output/4;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void cudaAveragePooling2(float *A, float *Output, int n_channels, int A_size){\n",
        "/*\n",
        "Average pooling of the input matrix by a factor of two in both dimensions, using CUDA on GPU.\n",
        "We assume n_channels=gridDim.x Output_size=blockDim.x and Output_size=blockDim.y\n",
        "We have channel_no=blockIdx.x horizontal_block_id=threadIdx.x and vertical_block_id=threadIdx.y\n",
        "Each thread computes a block\n",
        "\n",
        "Inputs:\n",
        "\t-A: Array initialized by dynamic memory allocation (float*) A = (float*) malloc(n_channels*n*p*sizeof(float))\n",
        "\t-Output: Output array, of size n_channels*(A_size/2)*(A_size/2)\n",
        "\t-n_channels: number of channels of A and Output, e.g 6 in the Lenet5 example\n",
        "\t-A_size: number of lines and columns of each channel of A, e.g 28 in the Lenet5 example.\n",
        "\tEach channel is assumed to be a square matrix.\n",
        "\n",
        "Example:\n",
        "\t-If Mat is of size 6*28*28 (Lenet5), output is of size 6*14*14, with averaging of each 2*2 block.\n",
        "*/\n",
        "\n",
        "\tint Output_size = A_size/2;\n",
        "\tint channel_no = blockIdx.x;\n",
        "\tint horizontal_block_id = threadIdx.x;\n",
        "\tint vertical_block_id = threadIdx.y;\n",
        "\tint output_index = channel_no*Output_size*Output_size + horizontal_block_id*Output_size + vertical_block_id;\n",
        "\n",
        "\t//compute sum over 4*4 block\n",
        "\tfloat block_output=0; //sum of 4*4 block\n",
        "\tfor (int i=0;i<2;i++){\n",
        "\t\tfor (int j=0;j<2;j++){\n",
        "\t\t\tblock_output=block_output + *(A+ channel_no*A_size*A_size + (2*horizontal_block_id+i)*A_size + 2*vertical_block_id+j);\n",
        "\t\t}\n",
        "\t}\n",
        "\tOutput[output_index]=block_output/4;\n",
        "}\n",
        "\n",
        "// __device__ â€‹ double tanh ( double  x ) is already defined in CUDA toolkit.\n",
        "// we just need to cast it to float\n",
        "__device__ float activation_tanh(float M){\n",
        "\treturn (float) tanh((double) M);\n",
        "}\n",
        "\n",
        "void matrixPrint(float *M, int n, int p){\n",
        "/*\n",
        "Prints the content of matrix M.\n",
        "\n",
        "Inputs:\n",
        "\t-M: Matrix initialized by dynamic memory allocation (float*) M = (float*) malloc(n*p*sizeof(float))\n",
        "\t-n: number of lines of M\n",
        "\t-p: number of columns of M\n",
        "*/\n",
        "\tfor (int i=0;i<n;i++){\n",
        "\t\tfor(int j=0;j<p;j++){\n",
        "\t\t\tprintf(\"%f\\t\",*(M+i*p+j));\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "}\n",
        "\n",
        "void printChannel(float *A, int channel_no, int n, int p){\n",
        "/*\n",
        "Prints the content of channel channel_no of array A.\n",
        "\n",
        "Inputs:\n",
        "\t-A: Array initialized by dynamic memory allocation (float*) A = (float*) malloc(n_channels*n*p*sizeof(float))\n",
        "\t-channel_no: number of the channel to display, 0 < channel_no < n_channels-1.\n",
        "\t-n: number of lines of each channel of A\n",
        "\t-p: number of columns of each channel of A\n",
        "*/\n",
        "\tint counter=0;\n",
        "\tfor (int i=0;i<n;i++){\n",
        "\t\tfor(int j=0;j<p;j++){\n",
        "\t\t\tprintf(\"%f\\t\",*(A+channel_no*n*p+i*p+j));\n",
        "\t\t\tcounter++;\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "\t//float* shared_memory_cpu=(float*)malloc(2*2*2*sizeof(float)); //2*Kernel_size*Kernel_size for array C as Kernels (2*2*2)\n",
        "\t//float* shared_memory;\n",
        "\t//cudaMalloc(&shared_memory, 2*2*2*sizeof(float));\n",
        "\t//cudaMemcpy(shared_memory, shared_memory_cpu, 2*2*2*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\t//Uncomment code below to prove Conv2D, cudaConv2D, AveragePooling2, cudaAveragePooling2 are functional\n",
        "\tfloat* A0=(float*)malloc(1*1*4*4*sizeof(float));\n",
        "\tfloat* A=(float*)malloc(2*4*4*sizeof(float));\n",
        "\tfloat* B=(float*)malloc(1*1*2*2*sizeof(float));\n",
        "\tfloat* C=(float*)malloc(2*2*2*2*sizeof(float));\n",
        "\tfloat* bias=(float*)malloc(2*sizeof(float));\n",
        "\t*A0=1;*(A0+1)=2;*(A0+2)=3;*(A0+3)=4;*(A0+4)=5;*(A0+5)=6;*(A0+6)=7;*(A0+7)=8;*(A0+8)=9;*(A0+9)=10;*(A0+10)=11;*(A0+11)=12;*(A0+12)=13;*(A0+13)=14;*(A0+14)=15;*(A0+15)=16;\n",
        "\t*A=1;*(A+1)=2;*(A+2)=3;*(A+3)=4;*(A+4)=5;*(A+5)=6;*(A+6)=7;*(A+7)=8;*(A+8)=9;*(A+9)=10;*(A+10)=11;*(A+11)=12;*(A+12)=13;*(A+13)=14;*(A+14)=15;*(A+15)=16;\n",
        "\t*(A+16)=1;*(A+17)=0;*(A+18)=0;*(A+19)=0;*(A+20)=0;*(A+21)=1;*(A+22)=0;*(A+23)=0;*(A+24)=0;*(A+25)=0;*(A+26)=1;*(A+27)=0;*(A+28)=0;*(A+29)=0;*(A+30)=0;*(A+31)=1;\n",
        "\t*B=1;*(B+1)=0;*(B+2)=0;*(B+3)=1;\n",
        "\t*C=1;*(C+1)=0;*(C+2)=0;*(C+3)=1;*(C+4)=2;*(C+5)=0;*(C+6)=0;*(C+7)=2;*(C+8)=2;*(C+9)=0;*(C+10)=0;*(C+11)=2;*(C+12)=1;*(C+13)=0;*(C+14)=0;*(C+15)=1;\n",
        "\t*bias=1;*(bias+1)=2;\n",
        "\tfloat* out=(float*)malloc(9*sizeof(float)); //A0 conv B on CPU\n",
        "\tfloat* AcC_cpu=(float*)malloc(18*sizeof(float)); //A conv C on CPU\n",
        "\tfloat* oout=(float*)malloc(8*sizeof(float)); //subsampled A on CPU\n",
        "\tfloat* out_from_gpu=(float*)malloc(9*sizeof(float)); //A0 conv B on GPU\n",
        "\tfloat* oout_from_gpu=(float*)malloc(8*sizeof(float)); //subsampled A on GPU\n",
        "\tfloat* AcC_from_gpu=(float*)malloc(18*sizeof(float)); //A conv C on GPU\n",
        "\tfloat* Aplusbias=(float*)malloc(2*4*4*sizeof(float)); //A plus bias on CPU\n",
        "\tfloat* Aplusbias_from_gpu=(float*)malloc(2*4*4*sizeof(float));\n",
        "\tfloat* tanhA=(float*)malloc(2*4*4*sizeof(float));\n",
        "\tfloat* tanhA_from_gpu=(float*)malloc(2*4*4*sizeof(float));\n",
        "\tfloat *d_A0,*d_A, *d_B,*d_C,*d_out,*d_oout,*d_AcC_gpu,*d_Aplusbias,*d_bias,*d_tanhA;\n",
        "\tcudaMalloc(&d_A0, 16*sizeof(float));\n",
        "\tcudaMalloc(&d_A, 32*sizeof(float));\n",
        "\tcudaMalloc(&d_B, 4*sizeof(float));\n",
        "\tcudaMalloc(&d_C, 16*sizeof(float));\n",
        "\tcudaMalloc(&d_out, 9*sizeof(float));\n",
        "\tcudaMalloc(&d_oout, 8*sizeof(float));\n",
        "\tcudaMalloc(&d_AcC_gpu, 18*sizeof(float));\n",
        "\tcudaMalloc(&d_Aplusbias, 2*4*4*sizeof(float));\n",
        "\tcudaMalloc(&d_tanhA, 2*4*4*sizeof(float));\n",
        "\tcudaMalloc(&d_bias, 2*sizeof(float));\n",
        "\tcudaMemcpy(d_A0, A0, 16*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_A, A, 32*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, 4*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_C, C, 16*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_out, out, 9*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_oout, oout, 8*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_AcC_gpu, AcC_from_gpu, 18*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_Aplusbias, Aplusbias_from_gpu, 2*4*4*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_bias, bias, 2*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_tanhA, tanhA, 2*4*4*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\tprintf(\"A0[:,:]=\\n\");\n",
        "\tmatrixPrint(A0, 4, 4);\n",
        "\tprintf(\"\\nB[:,:]=\\n\");\n",
        "\tmatrixPrint(B, 2, 2);\n",
        "\tprintf(\"\\nA[0,:,:]=\\n\");\n",
        "\tprintChannel(A,0,4,4);\n",
        "\tprintf(\"\\nA[1,:,:]=\\n\");\n",
        "\tprintChannel(A,1,4,4);\n",
        "\tprintf(\"\\nC[0,0,:,:]=\\n\");\n",
        "\tprintChannel(C,0,2,2);\n",
        "\tprintf(\"\\nC[0,1,:,:]=\\n\");\n",
        "\tprintChannel(C,1,2,2);\n",
        "\tprintf(\"\\nC[1,0,:,:]=\\n\");\n",
        "\tprintChannel(C,2,2,2);\n",
        "\tprintf(\"\\nC[1,1,:,:]=\\n\");\n",
        "\tprintChannel(C,3,2,2);\n",
        "\tprintf(\"\\nbias=\\n\");\n",
        "\tmatrixPrint(bias,1,2);\n",
        "\n",
        "\tConv2D(A0,B,out,1,1,4,2);\n",
        "\tConv2D(A,C,AcC_cpu,2,2,4,2);\n",
        "\tdim3 gridSizeA0(3,3,1);\n",
        "\tdim3 blockSizeA0(1,1,1);\n",
        "\tcudaConv2D<<<gridSizeA0,blockSizeA0,2*2*2*sizeof(float)>>>(d_A0,d_B,d_out,1,1,4,2);\n",
        "\tcudaMemcpy(out_from_gpu, d_out, 9*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tdim3 gridSizeA(3,3);\n",
        "\tdim3 blockSizeA(2,2);\n",
        "\tcudaConv2D<<<gridSizeA,blockSizeA,2*2*2*sizeof(float)>>>(d_A,d_C,d_AcC_gpu,2,2,4,2);\n",
        "\tcudaMemcpy(AcC_from_gpu, d_AcC_gpu, 18*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tAveragePooling2(A, oout, 2, 4);\n",
        "\tdim3 gridSize(2,1,1);\n",
        "\tdim3 blockSize(4,4,1);\n",
        "\tcudaAveragePooling2<<<gridSize,blockSize>>>(d_A,d_oout,2,4);\n",
        "\tcudaMemcpy(oout_from_gpu, d_oout, 8*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tAddBias(A,bias,Aplusbias,2,4);\n",
        "\tcudaAddBias<<<gridSize,blockSize>>>(d_A,d_bias,d_Aplusbias,2,4);\n",
        "\tcudaMemcpy(Aplusbias_from_gpu, d_Aplusbias, 32*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\tTanh3D(A,tanhA,2,4);\n",
        "\tcudaTanh3D<<<gridSize,blockSize>>>(d_A,d_tanhA,2,4);\n",
        "\tcudaMemcpy(tanhA_from_gpu, d_tanhA, 32*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tprintf(\"\\nA0 conv B on CPU:\\n\");\n",
        "\tmatrixPrint(out, 3, 3);\n",
        "\tprintf(\"\\nA0 conv B on GPU:\\n\");\n",
        "\tmatrixPrint(out_from_gpu, 3, 3);\n",
        "\tprintf(\"\\nA conv C on CPU (2 in channels, 2 out channel) - 1st output channel:\\n\");\n",
        "\tprintChannel(AcC_cpu,0,3,3);\n",
        "\tprintf(\"\\nA conv C on CPU (2 in channels, 2 out channel) - 2nd output channel:\\n\");\n",
        "\tprintChannel(AcC_cpu,1,3,3);\n",
        "\tprintf(\"\\nA conv C on GPU (2 in channels, 2 out channel) - 1st output channel:\\n\");\n",
        "\tprintChannel(AcC_from_gpu,0,3,3);\n",
        "\tprintf(\"\\nA conv C on GPU (2 in channels, 2 out channel) - 2nd output channel:\\n\");\n",
        "\tprintChannel(AcC_from_gpu,1,3,3);\n",
        "\tprintf(\"\\n2x2 average pooling of A on CPU:\\n\");\n",
        "\tprintf(\"\\nAp[0,:,:]\\n\");\n",
        "\tprintChannel(oout,0,2,2);\n",
        "\tprintf(\"\\nAp[1,:,:]\\n\");\n",
        "\tprintChannel(oout,1,2,2);\n",
        "\tprintf(\"\\n2x2 average pooling of A on GPU:\\n\");\n",
        "\tprintf(\"\\nAp[0,:,:]\\n\");\n",
        "\tprintChannel(oout_from_gpu,0,2,2);\n",
        "\tprintf(\"\\nAp[1,:,:]\\n\");\n",
        "\tprintChannel(oout_from_gpu,1,2,2);\n",
        "\tprintf(\"\\nA plus bias on CPU - 1st channel:\\n\");\n",
        "\tprintChannel(Aplusbias,0,4,4);\n",
        "\tprintf(\"\\nA plus bias on CPU - 2nd channel:\\n\");\n",
        "\tprintChannel(Aplusbias,1,4,4);\n",
        "\tprintf(\"\\nA plus bias on GPU - 1st channel:\\n\");\n",
        "\tprintChannel(Aplusbias_from_gpu,0,4,4);\n",
        "\tprintf(\"\\nA plus bias on GPU - 2nd channel:\\n\");\n",
        "\tprintChannel(Aplusbias_from_gpu,1,4,4);\n",
        "\n",
        "\t//initialize random number generator\n",
        "\t/*\n",
        "\ttime_t t;\n",
        "\tsrand((unsigned) time(&t));\n",
        "\n",
        "\t//initializing 2D and 3D arrays\n",
        "\tint raw_data_n=32;\n",
        "\tfloat* raw_data=(float*)malloc(raw_data_n*raw_data_n*sizeof(float));\n",
        "\trandomMatrixInit(raw_data, raw_data_n, raw_data_n);\n",
        "\tfloat* d_raw_data;\n",
        "\tcudaMalloc(&d_raw_data,raw_data_n*raw_data_n*sizeof(float));\n",
        "\tcudaMemcpy(d_raw_data, raw_data, raw_data_n*raw_data_n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\tint C1_data_n=28;\n",
        "\tint C1_data_n_channels=6;\n",
        "\tfloat* C1_data=(float*) malloc(C1_data_n_channels*C1_data_n*C1_data_n*sizeof(float));\n",
        "\tzero3DArrayInit(C1_data, C1_data_n_channels, C1_data_n, C1_data_n);\n",
        "\tfloat* d_C1_data;\n",
        "\tcudaMalloc(&d_C1_data,C1_data_n_channels*C1_data_n*C1_data_n*sizeof(float));\n",
        "\tcudaMemcpy(d_C1_data, C1_data, C1_data_n_channels*C1_data_n*C1_data_n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\tint C1_kernel_n=5;\n",
        "\tint C1_kernel_n_in_channels=1;\n",
        "\tint C1_kernel_n_out_channels=C1_data_n_channels;\n",
        "\tint C1_kernel_size=C1_kernel_n_out_channels*C1_kernel_n_in_channels*C1_kernel_n*C1_kernel_n*sizeof(float);\n",
        "\tfloat* C1_kernel=(float*)malloc(C1_kernel_size);\n",
        "\trandom4DArrayInit(C1_kernel, C1_kernel_n_in_channels, C1_kernel_n_out_channels, C1_kernel_n, C1_kernel_n);\n",
        "\tfloat* d_C1_kernel;\n",
        "\tcudaMalloc(&d_C1_kernel,C1_kernel_size);\n",
        "\tcudaMemcpy(d_C1_kernel, C1_kernel, C1_kernel_size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tint S2_data_n=C1_data_n/2;\n",
        "\tint S2_data_n_channels=C1_data_n_channels;\n",
        "\tfloat* S2_data=(float*)malloc(S2_data_n_channels*S2_data_n*S2_data_n*sizeof(float));\n",
        "\tzero3DArrayInit(S2_data, S2_data_n_channels, S2_data_n, S2_data_n);\n",
        "\tfloat* d_S2_data;\n",
        "\tcudaMalloc(&d_S2_data,S2_data_n_channels*S2_data_n*S2_data_n*sizeof(float));\n",
        "\tcudaMemcpy(d_S2_data, S2_data, S2_data_n_channels*S2_data_n*S2_data_n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\tint C3_data_n=10;\n",
        "\tint C3_data_n_channels=16;\n",
        "\tfloat* C3_data=(float*) malloc(C3_data_n_channels*C3_data_n*C3_data_n*sizeof(float));\n",
        "\tzero3DArrayInit(C3_data, C3_data_n_channels, C3_data_n, C3_data_n);\n",
        "\tfloat* d_C3_data;\n",
        "\tcudaMalloc(&d_C3_data,C3_data_n_channels*C3_data_n*C3_data_n*sizeof(float));\n",
        "\tcudaMemcpy(d_C3_data, C3_data, C3_data_n_channels*C3_data_n*C3_data_n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\tint C3_kernel_n=5;\n",
        "\tint C3_kernel_n_in_channels=S2_data_n_channels;\n",
        "\tint C3_kernel_n_out_channels=C3_data_n_channels;\n",
        "\tint C3_kernel_size=C3_kernel_n_out_channels*C3_kernel_n_in_channels*C3_kernel_n*C3_kernel_n*sizeof(float);\n",
        "\tfloat* C3_kernel=(float*)malloc(C3_kernel_size);\n",
        "\trandom4DArrayInit(C3_kernel, C3_kernel_n_in_channels, C3_kernel_n_out_channels, C3_kernel_n, C3_kernel_n);\n",
        "\tfloat* d_C3_kernel;\n",
        "\tcudaMalloc(&d_C3_kernel,C3_kernel_size);\n",
        "\tcudaMemcpy(d_C3_kernel, C3_kernel, C3_kernel_size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tint S4_data_n=C3_data_n/2;\n",
        "\tint S4_data_n_channels=C3_data_n_channels;\n",
        "\tfloat* S4_data=(float*)malloc(S4_data_n_channels*S4_data_n*S4_data_n*sizeof(float));\n",
        "\tzero3DArrayInit(S4_data, S4_data_n_channels, S4_data_n, S4_data_n);\n",
        "\tfloat* d_S4_data;\n",
        "\tcudaMalloc(&d_S4_data,S4_data_n_channels*S4_data_n*S4_data_n*sizeof(float));\n",
        "\tcudaMemcpy(d_S4_data, S4_data, S4_data_n_channels*S4_data_n*S4_data_n*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\t//First convolution\n",
        "\tdim3 gridSizeC1(C1_data_n_channels,1,1);\n",
        "\tdim3 blockSizeC1(C1_data_n,C1_data_n,1);\n",
        "\tcudaConv2D<<<gridSizeC1,blockSizeC1>>>(d_raw_data,d_C1_kernel,d_C1_data,1,C1_data_n_channels,raw_data_n,C1_kernel_n);\n",
        "\tcudaMemcpy(C1_data, d_C1_data, C1_data_n_channels*C1_data_n*C1_data_n*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\t//Average pooling\n",
        "\tdim3 gridSize2(C1_data_n_channels,1,1);\n",
        "\tdim3 blockSize2(S2_data_n,S2_data_n,1);\n",
        "\tcudaAveragePooling2<<<gridSize2,blockSize2>>>(d_C1_data,d_S2_data,C1_data_n_channels,C1_data_n);\n",
        "\tcudaMemcpy(S2_data, d_S2_data, C1_data_n_channels*S2_data_n*S2_data_n*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\t*/\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0tmlKrBwN5n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}